{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import datasets\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_digits\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored,cprint\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K Nearest Neighbours Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################  Euclidean Distance   #########################\n",
    "\n",
    "def euclideanDistance(x1, x2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow((x1[x] - x2[x]), 2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################  FInd the Neighbors   #########################\n",
    "\n",
    "\n",
    "def Find_Neighbors(trainingSet, testData, k):\n",
    "    distances = []\n",
    "    \n",
    "    length = len(testData)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testData, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################### Predict the data   ########################\n",
    "\n",
    "def Predict(neighbors):\n",
    "    class_votes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in class_votes:\n",
    "            class_votes[response] += 1\n",
    "        else:\n",
    "            class_votes[response] = 1\n",
    "    sorted_votes = sorted(class_votes.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_votes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################  Find Accuracy of My model     ############################\n",
    "\n",
    "\n",
    "def Find_Accuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        \n",
    "        if testSet[x] == predictions[x]:\n",
    "            correct += 1\n",
    "            print colored(\">>Predicted Result {0} and Actual Result {1}\" \\\n",
    "                          .format(predictions[x],testSet[x]),'green')\n",
    "    \n",
    "        else:\n",
    "            #pass\n",
    "            cprint(\">>Predicted Result {0} and Actual Result {1}\" \\\n",
    "                          .format(predictions[x],testSet[x]),None,'on_red')\n",
    "\n",
    "    return ((correct/float(len(testSet))) * 100.0),correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of digits in dataset Counter({1: 7877, 7: 7293, 3: 7141, 2: 6990, 9: 6958, 0: 6903, 6: 6876, 8: 6825, 4: 6824, 5: 6313})\n"
     ]
    }
   ],
   "source": [
    "##############################  MNIST Digit Training Part for HOG Features  #####################################\n",
    "\n",
    "# Hog Fetures are used for Object Detection. So as our project is about Handwritten digit recognition, we have \n",
    "#     used Hog feature.  \n",
    "\n",
    "\n",
    "# digits = load_digits()\n",
    "# np.unique(digits.target)\n",
    "\n",
    "# features = np.array(digits.data, 'int16') \n",
    "# labels = np.array(digits.target, 'int')\n",
    "# #print features[0].shape\n",
    "\n",
    "# list_hog_fd = []\n",
    "# for feature in features:\n",
    "#     fd = hog(feature.reshape((8, 8)), orientations = 9, pixels_per_cell=(4, 4), \\\n",
    "#              cells_per_block=(1, 1), visualise=False)\n",
    "#     list_hog_fd.append(fd)\n",
    "# hog_features = np.array(list_hog_fd, 'float64')\n",
    "\n",
    "\n",
    "\n",
    "dataset = datasets.fetch_mldata(\"MNIST Original\")\n",
    "\n",
    "# Extract the features and labels\n",
    "features = np.array(dataset.data, 'int16') \n",
    "labels = np.array(dataset.target, 'int')\n",
    "\n",
    "# print features[0].shape\n",
    "# Extract the hog features\n",
    "list_hog_fd = []\n",
    "for feature in features:\n",
    "    # Hog Feature for object Identification\n",
    "    fd = hog(feature.reshape((28, 28)), orientations=9, pixels_per_cell=(14, 14), \\\n",
    "             cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "\n",
    "# Count the number of Samples for every digit\n",
    "print \"Count of digits in dataset\", Counter(labels)\n",
    "accuracy = 0.0\n",
    "\n",
    "X,Y = hog_features,labels\n",
    "Y = Y.reshape(Y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 36), (70000, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part for Handwriten Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1) (100, 36)\n"
     ]
    }
   ],
   "source": [
    "X_Train, X_Test = X[:60000], X[69900:]\n",
    "Y_Train, Y_Test = Y[:60000], Y[69900:]\n",
    "\n",
    "\n",
    "print Y_Train.shape,X_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 8.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 0.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 0.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 8.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 0.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 6.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\n",
      "\n",
      "89 test cases classified correctly out of 100 with an efficiency of 89.0 %\n"
     ]
    }
   ],
   "source": [
    "y_predictions = []\n",
    "y_test = []\n",
    "\n",
    "trainingSet = np.concatenate((X_Train, Y_Train), axis=1)\n",
    "testSet = np.concatenate((X_Test, Y_Test), axis=1)\n",
    "predictions=[]\n",
    "k = 3\n",
    "\n",
    "for x in range(len(testSet)):\n",
    "    neighbors = Find_Neighbors(trainingSet, testSet[x], k)\n",
    "\n",
    "    result = Predict(neighbors)\n",
    "\n",
    "    y_predictions.append(repr(result))\n",
    "    y_test.append(repr(testSet[x][-1]))\n",
    "    \n",
    "accuracy,correct = Find_Accuracy(y_test, y_predictions)\n",
    "\n",
    "print \"\\n\\n\" + str(correct) + \" test cases classified correctly out of \" + \\\n",
    "        str(len(y_test)) + \" with an efficiency of \" + \\\n",
    "            str(accuracy) + \" %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 36), (70000, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Handwritten Digit Testing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "2.0\n",
      "5.0\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "8.0\n",
      "9.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "########################################  Photo 1 Testing part    ########################################## \n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"photo_1.jpg\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Show the Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "# Training the MNIST dataset\n",
    "trainingSet = np.concatenate((X, Y), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    # Draw the rectangle around the digit..\n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (4, 4))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    \n",
    "    k = 3\n",
    "    \n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    neighbors = Find_Neighbors(trainingSet, roi_hog_fd, k)\n",
    "    \n",
    "    result = Predict(neighbors)\n",
    "    \n",
    "    print result\n",
    "    \n",
    "    cv2.putText(im, str(int(result)), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 255), 3)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One More Testing Image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "5.0\n",
      "2.0"
     ]
    }
   ],
   "source": [
    "####################################  Harsh Handwritting Testing part    #################################### \n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"harsh.png\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours in the image\n",
    "cv2.imshow(\"Threshold\",im_th)\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "trainingSet = np.concatenate((X, Y), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (4, 4))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    #print roi_hog_fd\n",
    "    k = 3\n",
    "    \n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    neighbors = Find_Neighbors(trainingSet, roi_hog_fd, k)\n",
    "    \n",
    "    result = Predict(neighbors)\n",
    "    \n",
    "    print result\n",
    "    \n",
    "    cv2.putText(im, str(int(result)), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Testing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "5.0\n",
      "3.0\n",
      "7.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "###################################   Other Handwritting Digit Testing part    ################################### \n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"parikh.png\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 190, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cv2.imshow(\"Threshold\",im_th)\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "trainingSet = np.concatenate((X, Y), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (5, 5))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    \n",
    "    k = 3\n",
    "\n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    neighbors = Find_Neighbors(trainingSet, roi_hog_fd, k)\n",
    "    \n",
    "    result = Predict(neighbors)\n",
    "    \n",
    "    print result\n",
    "    \n",
    "    cv2.putText(im, str(int(result)), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now comes to Letter Recognition Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 1) (100, 16)\n"
     ]
    }
   ],
   "source": [
    "##############################     Letter Recognition Training Part    ##################################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Letter Dataset \n",
    "# https://archive.ics.uci.edu/ml/datasets/Letter+Recognition\n",
    "\n",
    "fname = 'letter-recognition.data'\n",
    "\n",
    "data = np.loadtxt(fname, np.float32, delimiter=',', converters={ 0 : lambda ch : ord(ch)-ord('A') })\n",
    "\n",
    "X_letter,Y_letter = data[:,1:],data[:,0]\n",
    "Y_letter = Y_letter.reshape(Y_letter.shape[0],1)\n",
    "\n",
    "X_Train, X_Test = X_letter[:19000], X_letter[19900:]\n",
    "Y_Train, Y_Test = Y_letter[:19000], Y_letter[19900:]\n",
    "\n",
    "\n",
    "print Y_Train.shape,X_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result H and Actual Result H\u001b[0m\n",
      "\u001b[32m>>Predicted Result C and Actual Result C\u001b[0m\n",
      "\u001b[32m>>Predicted Result X and Actual Result X\u001b[0m\n",
      "\u001b[32m>>Predicted Result Y and Actual Result Y\u001b[0m\n",
      "\u001b[32m>>Predicted Result D and Actual Result D\u001b[0m\n",
      "\u001b[32m>>Predicted Result U and Actual Result U\u001b[0m\n",
      "\u001b[32m>>Predicted Result I and Actual Result I\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result G and Actual Result G\u001b[0m\n",
      "\u001b[32m>>Predicted Result U and Actual Result U\u001b[0m\n",
      "\u001b[32m>>Predicted Result X and Actual Result X\u001b[0m\n",
      "\u001b[41m>>Predicted Result B and Actual Result P\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result Y and Actual Result Y\u001b[0m\n",
      "\u001b[32m>>Predicted Result G and Actual Result G\u001b[0m\n",
      "\u001b[32m>>Predicted Result K and Actual Result K\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result N and Actual Result N\u001b[0m\n",
      "\u001b[32m>>Predicted Result M and Actual Result M\u001b[0m\n",
      "\u001b[32m>>Predicted Result G and Actual Result G\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result X and Actual Result X\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result P and Actual Result P\u001b[0m\n",
      "\u001b[32m>>Predicted Result K and Actual Result K\u001b[0m\n",
      "\u001b[41m>>Predicted Result O and Actual Result W\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result H and Actual Result H\u001b[0m\n",
      "\u001b[32m>>Predicted Result W and Actual Result W\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result Y and Actual Result Y\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result G and Actual Result G\u001b[0m\n",
      "\u001b[32m>>Predicted Result E and Actual Result E\u001b[0m\n",
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result N and Actual Result N\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result M and Actual Result M\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result A and Actual Result A\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result N and Actual Result N\u001b[0m\n",
      "\u001b[32m>>Predicted Result F and Actual Result F\u001b[0m\n",
      "\u001b[32m>>Predicted Result P and Actual Result P\u001b[0m\n",
      "\u001b[32m>>Predicted Result U and Actual Result U\u001b[0m\n",
      "\u001b[32m>>Predicted Result H and Actual Result H\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result B and Actual Result B\u001b[0m\n",
      "\u001b[32m>>Predicted Result F and Actual Result F\u001b[0m\n",
      "\u001b[32m>>Predicted Result E and Actual Result E\u001b[0m\n",
      "\u001b[32m>>Predicted Result F and Actual Result F\u001b[0m\n",
      "\u001b[32m>>Predicted Result A and Actual Result A\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result C and Actual Result C\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result F and Actual Result F\u001b[0m\n",
      "\u001b[32m>>Predicted Result C and Actual Result C\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result N and Actual Result N\u001b[0m\n",
      "\u001b[32m>>Predicted Result E and Actual Result E\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result A and Actual Result A\u001b[0m\n",
      "\u001b[32m>>Predicted Result K and Actual Result K\u001b[0m\n",
      "\u001b[32m>>Predicted Result M and Actual Result M\u001b[0m\n",
      "\u001b[32m>>Predicted Result R and Actual Result R\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result Y and Actual Result Y\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result M and Actual Result M\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result D and Actual Result D\u001b[0m\n",
      "\u001b[41m>>Predicted Result F and Actual Result P\u001b[0m\n",
      "\u001b[32m>>Predicted Result W and Actual Result W\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result E and Actual Result E\u001b[0m\n",
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result D and Actual Result D\u001b[0m\n",
      "\u001b[32m>>Predicted Result C and Actual Result C\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result A and Actual Result A\u001b[0m\n",
      "\n",
      "\n",
      "97 test cases classified correctly out of 100 with an efficiency of 97.0 %\n"
     ]
    }
   ],
   "source": [
    "##############################     Letter Recognition Testing Part    ##################################\n",
    "\n",
    "\n",
    "\n",
    "accuracy = 0.0\n",
    "y_predictions = []\n",
    "y_test = []\n",
    "\n",
    "trainingSet = np.concatenate((X_Train, Y_Train), axis=1)\n",
    "testSet = np.concatenate((X_Test, Y_Test), axis=1)\n",
    "predictions=[]\n",
    "k = 3\n",
    "\n",
    "for x in range(len(testSet)):\n",
    "    neighbors = Find_Neighbors(trainingSet, testSet[x], k)\n",
    "    result = Predict(neighbors)\n",
    "    y_predictions.append(chr(int(result)+65))\n",
    "    y_test.append(chr(int(testSet[x][-1])+65))\n",
    "        \n",
    "accuracy,correct = Find_Accuracy(y_test, y_predictions)\n",
    "\n",
    "#print \"\\n\\nAccuracy is {0} %\".format(accuracy)\n",
    "\n",
    "print \"\\n\\n\" + str(correct) + \" test cases classified correctly out of \" + \\\n",
    "        str(len(y_test)) + \" with an efficiency of \" + \\\n",
    "            str(accuracy) + \" %\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for HOG Feature for Letter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before X Features Dimention\n",
      "(20000, 16)\n",
      "\n",
      "After X Features Dimention\n",
      "(20000, 36)\n"
     ]
    }
   ],
   "source": [
    "########################  Letter Recognition Training Part for HOG Features #########################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "fname = 'letter-recognition.data'\n",
    "\n",
    "data = np.loadtxt(fname, np.float32, delimiter=',', converters={ 0 : lambda ch : ord(ch)-ord('A') })\n",
    "\n",
    "X_letter,Y_letter = data[:,1:],data[:,0]\n",
    "\n",
    "X_letter = np.array(X_letter,'int16')\n",
    "Y_letter = np.array(Y_letter,'int')\n",
    "\n",
    "print \"Before X Features Dimention\"\n",
    "\n",
    "print X_letter.shape\n",
    "list_hog_fd = []\n",
    "\n",
    "for feature in X_letter:\n",
    "    # Hog Feature for object Identification\n",
    "    fd = hog(feature.reshape((4, 4)), orientations=9, pixels_per_cell=(2, 2), \\\n",
    "             cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "\n",
    "accuracy = 0.0\n",
    "\n",
    "print \"\\nAfter X Features Dimention\"\n",
    "\n",
    "print hog_features.shape\n",
    "\n",
    "X_letter = hog_features\n",
    "Y_letter = Y_letter.reshape(Y_letter.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 36), (20000, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_letter.shape,Y_letter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Testing Data for Letter Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "B\n",
      "K\n",
      "N\n",
      "A\n",
      "A\n",
      "Q\n",
      "B\n",
      "A\n",
      "D\n",
      "E\n",
      "W\n",
      "O\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "##################################   Handwritten Letters Testing part    #################################### \n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"dipen_letter.png\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "ret, im_th = cv2.threshold(im_gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Threshold\",im_th)\n",
    "\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "trainingSet = np.concatenate((X_letter, Y_letter), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (4, 4), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (3, 3))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(2, 2), cells_per_block=(1, 1), visualise=False)\n",
    "\n",
    "    k = 3\n",
    "    \n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    neighbors = Find_Neighbors(trainingSet, roi_hog_fd, k)\n",
    "    \n",
    "    result = Predict(neighbors)\n",
    "    print str(chr(int(result)+65))\n",
    "    cv2.putText(im, chr(int(result)+65), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Inbuilt Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy:  90.41 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "#########################  Inbuilt Method for KNN    ##########################\n",
    "\n",
    "# http://brianfarris.me/static/digit_recognizer.html\n",
    "\n",
    "\n",
    "x_train, x_test = X[:60000], X[60000:]\n",
    "y_train, y_test = Y[:60000], Y[60000:]\n",
    "\n",
    "\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(x_train, y_train)\n",
    "y_pred_knn = clf_knn.predict(x_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print \"K Nearest Neighbors Accuracy: \",(acc_knn*100), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
